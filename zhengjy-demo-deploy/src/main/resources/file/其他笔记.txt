NIO:
	NIO和IO的工作方式：IO（面向流），NIO（面向块）
		IO：基于字节字符流进行操作。
		NIO：基于管道(channel)和缓冲区(buffer)进行操作，数据总是从通道读取到缓冲区，或者从缓冲区写入到通道。
	异步IO：NIO可以异步的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情。当数据被写入到缓冲区，线程可以继续出来它。
	Selects(选择器)：NIO引入选择器的概念，选择器可以用于监听多个通道的事件。因此单个的线程可以监听多个数据通道。

	面向流与面向缓冲：NIO和IO之间最大的区别是，IO是面向流，NIO是面向缓冲区的。
		JAVA IO面向流意味着每次从流中读取一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它们不能前后移动流中的数据。
	如果需要前后移动从流中读取的数据，需要先将它缓存在一个缓冲区。
		JAVA NIO的缓冲导向方法略有不同。数据读取一个它稍后处理的缓冲区，需要时可在缓冲区前后移动。这增加了处理过程中的灵活性。但是，
	还需要先检查是否缓冲区中包含所有处理的数据。而且，需确保当更多的数据读入缓冲区时，不用覆盖缓冲区尚未处理的数据。

	阻塞IO与非阻塞IO：
		JAVA IO的各种流是阻塞的。当调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程不能干是他的事情。
		JAVA NIO的非阻塞模式，使用一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有可用的数据时，就什么都不会获取。
	而不是保持线程的阻塞，所以直至变的可读取之前，该线程可用继续做其他的事情。非阻塞写的也是如此。一个线程请求写入一些数据到某通道，但不需要
	等待他完全写入，这个线程同时可以去做别的事情。线程通常将非阻塞IO的空闲时间用于在其他通道上执行IO操作，所以一个单独线程可以管理多个输入和
	输出通道(channel)；

	选择器(selelctors)：
		JAVA NIO的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然后使用一个单独的线程来选择通道：这些通道里
	已经有可以处理的输入，或者选择已准备写入的通道。这种选择机制，使得一个单独的线程很容易来管理多个通道。
	
	什么是缓冲区：
		Buffer是一个对象，它包含一些要写入或刚读出的数据。在NIO中加入buffer对象，体现了新库与原IO的一个重要区别。在面向流的IO中，将数据直接写入或将数据直接读到流对象中。
		在NIO中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。任何时候访问NIO中的数据，都是将它放入缓冲区。
		缓冲区实质上是一个字节数组。
		
	什么是通道：
		Channel是一个对象，可以通过他读取和写入数据。拿NIO与原来的IO做比较，通道就像流。
		所有数据都通过Buffer对象处理。永远不会将字节直接写入通道中，相反，是将数据写入包含一个或多个字节的缓冲区。同样，不会直接从通道中读取字节，而是将数据从通道读入
		缓冲区，再从缓冲区获取这个字节。
		
		通道，被建立的一个应用程序和操作系统交互事件、传递内容的渠道（注意是连接到操作系统）。一个通道会有一个专属的文件状态描述符。
		那么既然是和操作系统进行内容的传递，那么说明应用程序可以通过通道读取数据，也可以通过通道向操作系统写数据。
	
	通道：
		既可以从通道读取数据，又可以写数据到通道。但流的读写通常是单向的。
		通道可以异步读写。
		通道中的数据总是要先读到一个buffer，或者从一个buffer中写入。
	
	通道类型：通道与流的不同之处在于通道是双向的。而流在一个方向像上移动，而通道可用于读、写或者同时读写。
	
	选择器：
		selector是java NIO中能够检测一个到多个NIO通道，并能够知晓通道是否为读写事件做好准备组件。这样，一个单独线程可以管理多个channel，从而管理多个网络链接。
		NIO服务端只需启动一个专门的线程来处理所有的IO事件。javaNIO采用了双向通道(channel)进行数据传输，而不是单向的流(strean)，在通道上可以注册我们感兴趣的事件。
		
		服务端和客户端各自维护一个管理通道的对象，我们称为selector,该对象能够检测一个或多个通道(channel)上的事件。如果服务端的selector上注册了读的事件，某时刻客户端
		给服务端发送了一些数据，阻塞IO这时会调用read()方法阻塞的读取数据，NIO的服务端会在selector中添加一个读事件。服务端的处理线程会轮询访问selector，如果访问selector
		时发现有感兴趣的事件到达，则处理这些事件，如果没有感兴趣的事件，则处理线程一直阻塞直到感兴趣的事件到达为止。
		
		selector”（选择器）。它负责代替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作
		
	总结：
		NIO可以让你使用一个或多个线程管理多个通道，解析数据会比一个阻塞流中读取复杂。
		如果需要管理同时打开的成千上万个连接，这些连接每次只发送少量的数据，如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要
	维持许多打开的连接到其他计算机上，使用一个单独的线程来管理你所有出站连接是一个优势。
	1、有一个专门的线程来处理所有的IO事件，并负责分发。
	2、事件驱动机制：事件到的时候去触发，而不是同步的去监听事件。
	3、线程通讯：线程之间通过 wait,notify等方式通讯。保证每次上下文切换都是有意义的。减少无谓的线程切换。

阻塞IO和非阻塞IO：这两个概念是程序级别的。描述程序请求操作系统IO操作后，如果IO资源没有准备好，程序该如何处理，前者等待，
					后者继续执行（并且使用线程一直轮询，知道IO资源准备好）
同步IO和非同步IO：这两个概念是系统级别的。描述操作系统在收到程序请求IO操作后，如果IO资源没有准备好，该如何相应处理，前者不响应，直到IO资源
					准备好以后;后者返回一个标识(好让程序和自己知道以后的数据往哪通知)，当IO资源准备好以后，再用事件机制返回给程序。

异步IO
	异步IO则是采用“订阅-通知”模式：即应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，
	在主动通知应用程序，触发相应的函数。
	
	在JAVA NIO框架中，我们说到了一个重要概念“selector”（选择器）。它负责代替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；
	但是在JAVA AIO框架中，由于应用程序不是“轮询”方式，而是订阅-通知方式，所以不再需要“selector”（选择器）了，改由channel通道直接到操作系统注册监听。

	JAVA AIO框架中，只实现了两种网络IO通道“AsynchronousServerSocketChannel”（服务器监听通道）、“AsynchronousSocketChannel”（socket套接字通道）。但是无论哪种通道他们都有独立的
	fileDescriptor（文件标识符）、attachment（附件，附件可以使任意对象，类似“通道上下文”），并被独立的SocketChannelReadHandle类实例引用。

IO模型
	阻塞和非阻塞：这个概念是针对应用程序而言，是指应用程序中的线程在向操作系统发送IO请求后，是否一直等待操作系统的IO响应。如果是，那么就是阻塞式的；如果不是，
					那么应用程序一般会以轮询的方式以一定周期询问操作系统，直到某次获得了IO响应为止（轮序间隔应用程序线程可以做一些其他工作）。

	同步和异步：IO操作都是由操作系统进行的（这里的IO操作是个广泛概念了：磁盘IO、网络IO都算），不同的操作系统对不同设备的IO操作都有不同的模式。同步和异步这两个概念都指代
				的操作系统级别，同步IO是指操作系统和设备进行交互时，必须等待一次完整的请求-响应完成，才能进行下一次操作（当然操作系统和设备本身也有很多技术加快这个反应过程，
				例如“磁盘预读”技术、数据缓存技术）；异步IO是指操作系统和设备进行交互时，不必等待本次得到响应，就可以直接进行下一次操作请求。设备处理完某次请求后，
				会主动给操作系统相应的响应通知。

	多路复用IO：多路复用IO，从本质上看还是一种同步IO，因为它没有100%消除IO_WAIT，操作系统也没有为它提供“主动通知”机制。但是多路复用IO的处理速度已经相当快了，
				利用设备执行IO操作的时间，操作系统可以继续执行IO请求。并同样采用周期性轮询的方式，获取一批IO操作请求的执行响应。
				操作系统支持的多路复用IO技术主要有select、poll、epoll、kqueue。

	阻塞式同步IO模型：这个从字面上就很好理解了，应用程序请求IO操作，并一直等待处理结果；操作系统同时也进行IO操作，并等待设备的处理结果；可以看出，应用程序的请求线程和
						操作系统的内核线程都是等待状态。

	非阻塞式同步IO模型：应用程序请求IO，并且不用一直等待返回结果就去做其他事情。隔一定的周期，再去询问操作系统上次IO操作有没有结果，直到某一次询问从操作系统拿到IO结果；
						操作系统内核线程在进行IO操作时，还是处理一直等待设备返回操作结果的状态。

	非阻塞式多路复用IO模型：应用程序请求IO的工作采用非阻塞方式进行；操作系统采用多路复用模式工作。

	非阻塞式异步IO模型：应用程序请求IO的工作采用非阻塞方式进行，但是不需要轮询了，因为操作系统异步IO其中一个主要特性就是：可以在有IO响应结果的时候，主动进行通知。

					
HTTP:是Hyper Text Transfer Protocol(超文本传输)的缩写
	HTTP是一个应用层协议，由请求和响应构成，是一个标准的客户端服务器模型。HTTP是一个无状态协议（同一个客户端的这次请求和上一次请求没有对应关系）。
	HTTP永远都是客户端发起请求，服务端响应。
	HTTP请求/响应的步骤：
		1)客户端连接到web服务器：一个HTTP客户端(浏览器)，与Web服务器的HTTP端口(默认80)建立一个TCP套接字连接。例如:http:www.baidu.com
		2)发送HTTP请求，通过TCP套接字：客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行、和请求数据4部分组成。
		3)服务器接受请求并返回HTTP响应：web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和
	响应数据4部分组成。
		4)释放连接TCP连接：web服务器主动关闭TCP套接字，释放TCP连接；客户端被动关闭TCP套接字。释放TCP连接。
		5)客户端浏览器解析HTML内容：客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每个响应头，响应头告知以下为若干字节的HTML文档和
	文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。
	
	TCP/IP的分层管理
		应用层；应用层决定了向用户提供应用服务时通信的活动。TCP/IP协议族内预存了各种通用的应用服务。FTP、DNS、HTTP
		传输层：传输层对上层应用层，提供处于网络连接中的两台计算机之间的数据传输
		网络层：网络层用来处理在网络上流动的数据包。数据包是网络传输的嘴角数据单位。该层规定了通过怎样的路径（传输路线）到达对方计算机，并把数据包传送个对方
		链路层：用来处理连接网络的硬件部分。

	http执行流程：
		首先客户端在应用层(HTTP协议)发出一个想看某个Web页面的HTTP请求。
		接着，为了传输方便，在传输层(TCP协议)把从应用层处收到的数据(HTTP请求报文)进行分割，并各个报文上打上标记序号及端口号后转发给网络层。
		在网络层(IP协议),增加作为通信目的地的MAC地址后转发给链路层。这样一来发往网络的通信请求就准备齐全了。
		接收端的服务器在链路层接收到数据，按序网上层发送，一直到应用层。当传输到应用层，才能算真正接收到客户端发送过来的HTTP请求。
	确保可靠性的TCP协议：按层次分，TCP位于传输层，提供可靠的字节流服务
		所谓的字节流服务是指，为了方便传输，将大块数据分割成以报文段为单位的数据包进行管理。而可靠的传输服务是指，能够把数据准确可靠的传输给对方。TCP协议是为了
		更容易传输大数据才把数据分割，而且TCP协议能够确认数据最终是否送达对方。
	确保数据能够达到目标：
		为了准确无误的将数据送达目标处，TCP采用三次握手策略。用TCP协议将数据包送出去后，TCP不会对传输后的情况置之不理，它一定会想对方确认是否成功送达。除了三
		次握手，TCP协议还有其他各种手段来保证通信的可靠性。
	负责域名解析的DNS服务:
		DNS服务是和HTTP协议一样位于应用层的协议。它提供域名到IP地址之间的解析服务。
	请求报文：请求报文是由请求方法、请求URL、协议版本、	可选的请求首部字段和内容实体构成的。

	HTTP报文：
		用于HTTP协议交互的信息被称为HTTP报文。客户端的HTTP报文叫请求报文。服务端的叫响应报文。HTTP报文本身由多行数据构成的字符串文本。HTTP报文大致可分为报文首部
	和报文主体两块。两者由最初出现的空行来划分。通常，并不一定要有报文主体。

	HTTP持久连接：
		持久连接的特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态。避免三次握手。持久化连接的好处在于减少TCP连接的重复建立和断开所造成的额外开销，
	减轻了服务端的负载。在HTTP/1.1中，所有的连接默认都是持久连接。
	
	HTTPS：加上加密处理和认证以及完整性保护既是HTTPS。所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP。

	HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。
	HTTP协议是一个无状态的协议，同一个客户端的这次请求和上次请求是没有对应关系。想要关联起来是需要Cookie和Session。


	HTTP/1.0
		在HTTP/1.0版本中，并没有官方的标准来规定Keep-Alive如何工作，因此实际上它是被附加到HTTP/1.0协议上，如果客户端浏览器支持Keep-Alive，那么就在HTTP请求头中添加一个字段 
	Connection: Keep-Alive，当服务器收到附带有Connection: Keep-Alive的请求时，它也会在响应头中添加一个同样的字段来使用Keep-Alive。这样一来，客户端和服务器之间的HTTP
	连接就会被保持，不会断开（超过Keep-Alive规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接
	HTTP/1.1
		在HTTP/1.1版本中，官方规定的Keep-Alive使用标准和在HTTP/1.0版本中有些不同，默认情况下所在HTTP1.1中所有连接都被保持，除非在请求头或响应头中指明要关闭：
	Connection: Close  ，这也就是为什么Connection: Keep-Alive字段再没有意义的原因。另外，还添加了一个新的字段Keep-Alive:，因为这个字段并没有详细描述用来做什么，可忽略它

		
Spring
	bean 是在什么时候被创建的，有哪些规则？
		容器初始化的时候会预先对单例和非延迟加载的对象进行预先初始化。其他的都是延迟加载是在第一次调用getBean 的时候被创建。

	1.容器启动阶段：Spring提供了两种方式的BeanDefinition解析器，PropertiesBeanDefinitionReader和XmlBeanDefinitionReader（org.xml.sax包）解析器，也可以自定义自己的解析器，他们
	都实现了BeanDefinitionReader。加载配置进行解析分析，并将分析后的信息编组为相应的BeanDefinition,注册到相应的BeanDifinitionRegister，存
	放到beanDefinitionMap(key为beanName,value为BeanDefinition)
		1)加载配置
		2)分析配置信息
		3)装备到BeanDefinition
		4)其他后处理
	2.容器实例化阶段：BeanDefinition注册到了BeanDefinitionRegister中之后，当某个请求通过容器的geBean方法明确的请求某个对象，容器会检查所请求的对象是否已经初始化。
	如果没有，则会根据注册的BeanDefinition所提供的信息实例化请求对象，并未其注入依赖。如果该对象实现了某些回调接口，也会根据回调接口的要求来装配他。当该对象装配完成
	后，容器会立即返回请求方使用。(如果装载A，会先装载A锁依赖的bean。)
		1)实例化对象
		2)装配依赖
		3)生命周期的回调
		4)对象其他处理
		5)注册回调接口
		
	为了给容器中定义的每个bean对应的实例注入依赖，可以遍历他们，通过反射检查每个bean定义对应的类上各种可能位置上的Autowired。如果存在的话就可以从当前容器管理的对象
	中获取符合条件的对象，设置给Autowired标注的地方。
		
	BeanFactoryPosProcessor：容器扩展机制。该机制允许我们在容器实例化对象之前，对注册容器的BeanDefinition所保存的信息做修改。比如修改bean定义的某些属性、增加其他信息
	如果要自定义需要实现这个接口。
	
	PropertyPlaceHolerConfigurer：在第一阶段加载完成所有的配置信息时，BeanDifinition中保存的对象属性信息还只是以占位符的形式存在，如${jdbc.url},PPHC会使用propertis配置
	文件中的配置信息来替换相应的BeanDefication中占位符所表示的属性值。
		
	AOP：Spring AOP采用动态带来机制和字节码生成技术(CGLIB)实现，动态带来和字节码生成都是在运行期间为目标生成一个代理对象，而将横切逻辑加入到这个代理对象中。系统最终
	使用的是加入横切逻辑代理对象，而不是真正的目标对象。如果目标对象没有实现任何接口，Spring AOP 会使用CGLIB(基于类的代理)
	
		
	Spring MVC:当我们对SpringMVC控制的资源发起请求时,这些请求都会被SpringMVC的DispatcherServlet处理，通过BeanNameUrlHandlerMapping找到对应的Controller，然后拿到这个
	Controller和每个adapter进行适配，找到SimpleControllerHandlerAdapter来完成对应请求的Controller的handlerRequest方法调度，然后就顺利的执行了我们想要的方法。方法
	会返回一个ModelAndView对象。在获得ModelAndView对象之后，Spring就需要把该View渲染给用户。在这个渲染的过程中，发挥作用的就是ViewResolver和View。当Handler返回
	ModelAndView中不包含真正的视图，只返回一个逻辑视图名称，ViewResolver就会把改视图名称解析为真正的视图View对象。View是真正进行视图渲染，把结果返回给浏览器的。
	
	浏览器发生请求连接，web请求将会被发送到DispatcherServlet进行处理。DispatcherServlet将寻求相应的HandlerMapping对web请求进行解析，然后调用请求结果对应的Controller
	实现，对应的Controller(请求目标Controller)处理完成将视图名称和模型数据一同返回，然后DispatcherServlet则借住于相应的ViewResolver，根据返回的视图名选择相应的
	视图并显示。
	
	Spring MVC 5大角色：HandlerMapping、Controller、ModelAndView、ViewResolver、View。
		 视图:
			Spring为我们提供了非常多的视图解析器。有一个AbstractCachingViewResolver抽象类，这种视图解析器会把曾经解析的视图保存下来，然后每次解析视图的时候先从缓存
		里面找，找到了对应的视图就直接返回，如果没有找到就创建一个新的视图对象。然后把他放到一个用于缓存的map中，接着再把新建的视图返回。这种可以降低性能。比较常用
		的InternalResourceViewResolver是使用比较广泛的视图解析器。InternalResourceViewResolver会把返回的视图名称解析为InternalResourceView对象，InternalResourceView
		会把Controller处理器方法返回的模型属性都放到对应的request属性中，然后通过RequestDispatcher在服务器端转发或重定向目标URL。
		
		获取Handler：(找到Controller)
		getHandler，通过遍历所有已经注册过的HandlerMapping来找到对应的Handler，然后构建出一个HandlerExecutionChain，
		他包含了handler和HandlerMaping本身的一些拦截器。
	
		HandlerMapping的getHandler实现：有一个getHandlerInternal(request)是个抽象方法，由具体的HandlerMapping
		来实现，获取到的handler如果为null，则取默认的handler。如果handler为String类型则去容器里面找这样名称的bean.
		
		BeanNameUrlHandlerMapping的getHandlerInternal(request)的具体实现,bean的name必须以/开头，他才处理，将信息存储到map中。
		
		获取HandlerAdapter：(找到Controller下的方法)
			同Handler遍历所有已经注册到容器的HandlerAdapter，找到HandlerAdapter。验证是否已实现了HandlerRequestHandler接口
			若已实现该接口则调用匹配到适配器的实现类下handle方法，执行逻辑。

		初始化HandlerMapping和HandlerAdapter：
			首先会判断delectAllHandlerMappings是否为true,如果为true，则会去本工程mvc-servlet.xml文件去探测所有实现
			了HandlerMapping的bean，如果有，则加入DispatcherServlet的HandlerMapprings集合中。如果delectAllHandlerMappings
			为false，则直接去容器中找id="handlerMapping"且实现了HandlerMappingg的bean，如果都没找到，则会去加载默认
			的HandlerMapping，会去读取DispatcherServlet.properties文件，里面有默认的BeanNameUrlHandlerMapping、
			HttpRequestHanderAdapter。
		
		HandlerMapping将会通过返回HandlerExecutionChain返回一个Controoler用于具体web请求的处理。可以不只是Controller
		一种类型。在Spring MVC中任何用于web请求处理的处理对象统称handler。Controller是Handler的一种特殊类型。HandlerMapping
		通过HandlerExecutionChain返回的一个Object类型的Handler对象，而并没有限制只能是Controller类型。

		HandlerExecutionChain就是一个数据载体，他包含了两方面的数据，一个用于处理Web请求的Handler,另一个则是一组
		随同Handler一起返回的HandlerInterceptor。这组HandlerInterceptor可以在Handler的执行前后对处理流程拦截操作。
		
		
		HandlerInterceptor:
		preHandle():该拦截方法将在相应的HandlerAdapter调用具体的Handler处理web请求之前执行。通过boolean判断
		是否往下执行。true，表明允许后继处理流程继续执行。false：不允许继续往下执行。
		postHandle():该拦截方法的执行时机为HandlerAdapter调用具体的Handler处理完web请求之后，并且在视图的解析
		和渲染之前。通过该方法我们可以获取Handler执行后的结果，即ModelAndView。我们可以在原处理结果的基础上对
		其进行进一步的处理，比如添加新的模型数据。返回为void，不可阻断后续处理。
		afterCompletion():在框架内整个流程处理完后，或者视图都渲染完了的时候，不管是否发生异常，都会执行。
		
		
		Filter位于DispatcherServlet之前。如果把Filter和HandlerInterceptor看作同一类型的拦截器，Filter将比HanlderInterceptor
		拥有更高的执行优先级。
		filter在servlet层面对DispatcherServlet进行拦截，而HandlerInterceptor则位于DispatcherServlet内部，对Handler
		的执行进行拦截。Filter的应用的位置注定了它不能提供细粒度的拦截时点。通常情况下，使用Filter对应web应用程序
		中的一些普遍关注点进行统一处理是比较合适的，一旦需要细化处理流程的拦截逻辑，则用HandlerInterceptor。

		Filter是servlet标准组件，需要在xml配置，其生命周期管理更多是由web容器进行管理的。
		
		文件上传与MultipartResolver
		html页面表单最初采用的是application/x-www-form-urlencoded编码方法，并不足以满足文件上传的需要，所以，RFC
		在基础上新增了multipart/form-data编码的方式以支持基于表单提交的方式支持文件上传。客户端浏览器将按照
		RFC1867所规定的格式，对提交的表单内容进行编码，服务器只需要根据RFC1867规定的格式对请求中的信息进行解码，
		就可以获得客户端表单提交的内容，包括上传的文件。
		
		MultipartResolver简单分析：
			当web请求到达DispatcherServlet并等候处理的时候，DispatcherServlet首先会去检查能否从自己的WebApplicationContext
		中找到一个名称为multipartResolver的MultipartResolver实例。如果能够获得一个实例，DispatcherServlet将通过
		MultipartResolver的isMultipart(request)方法检查当前web请求是否为multipart类型。如果是DispatcherServlet将调用
		MultipartResolver的resolverMultipart(request)方法，并返回MultipartHttpServletRequest供后继处理流程使用，否则
		直接返回HttpServlectRequest。当web类型为multipart的时候，MultipartResolver的resolverMultipart(request)所返回
		的MultipartHttpServlectRequest将被后继处理流程所依赖的HttpServletRequest而使用。也就是说对应的HttpServletRequest
		会被替换为MultipartHttpServletRequest，后续的处理的各个环节都是MultipartHttpServletRequest。
		MultipartResolver接口SpringMVC提供了两个可用的实现类。CommonsMultipartResolver、CosMultipartResolver	
		
			BeanFactoryPostProcessor 干预容器启动阶段，如PropertySourcesPlaceholderConfigurer,当BeanFactory在第一阶段加载
完所有配置信息时，BeanFactory中所保存的对象属性信息还只是以占位符的形式存在，如${jdbc.url}。当
PropertyPlaceholderConfigurer 作为 BeanFactoryPostProcessor 被应用时，他会使properties配置文件中的配置信息
来替换BeanDefinition中占位符所表示的属性值。这样，当进入容器实例的第二阶段实例化bean时，bean定义中的属性值
就是最终替换完成了


BeanPostProcessor存在与对象实例化阶段
BeanFactoryPostProcessor存在与容器启动阶段

spring数据准备阶段：首先对传入的参数resource参数做封装，目的是考虑到Resource可能存在编码要求的情况，其次，
通过SAX读取XML文件的方式做准备InputSource对象，最后将准备的数据通过参数真正核心处理的部分
doLoadBeanDefinition(inputSource,encodedResoure.getResource())。

		
序列化：
	将一个对象编码成一个字节流，称作将该对象序列化；相反的处理过程被称为反序列化。一旦对象被序列化后，它的编码就可以从一台正在运行的虚拟机被传递给另外一条虚拟机
	上，或者被存储到磁盘上，以供反序列化时用。
		
		http://www.cnblogs.com/yangy608/archive/2011/06/29/2093478.html
		
如果简单地比较Redis与Memcached的区别，大多数都会得到以下观点：

1 、Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。
2 、Redis支持数据的备份，即master-slave模式的数据备份。
3 、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。
		
netty
	netty的3种连接方式
		1)使用长连接通道不断开的形式进行通信，也就是说服务器和客户端的通道一直处于开启状态，如果服务器性能比较好，并且客户端数量也必将少的情况下，推荐这种方式。
		2)一次性批量提交数据，采用短连接方式。也就是说我们会把数据临时保存在本地缓冲区或者临时表，当达到临界线时一次性批量提交，又或者指定定时任务轮询提交，这种
			情况弊端是做不到实时性传输，在对实时性不高的应用程序中可以推荐使用。
		3)可以采用一种特殊的长连接，在指定的一个时间内，服务器和某台客户端没有任何通信，则断开连接。下次客户端发起请求的时候，在建立连接。
	
		一个Netty程序开始于Bootstrap类，Bootstrap类是Netty提供的一个可以通过简单配置来设置或引导程序的一个很重要的类。
Netty中设计了Handlers来处理特定的event和设置Netty中的事件，从而来处理多个协议和数据。事件可以描述成一个非常通
用的方法，因为你可以自定义一个handler，用来将Object转换byte[]或将byte[]转成Object;

EventLoopGroup和一个Channel关联一个单一的EventLoop,Netty中的EventLoopGroup包含一个或多个EventLoop，而EventLoop
就是一个Channel执行实际工作的线程。EventLoop总是绑定一个单一的线程，再其生命周期内不会改变。当注册一个Channel后
，Netty将这个Channel绑定到一个EventLoop，在Channel的生命周期内总是被绑定到一个EventLoop，在Netty IO操作中，你的
程序不需要同步，因为一个指定通道的所有IO始终由同一个线程来执行。


EventLoopGroup:
	EventLoopGroup包含多个EventLoop，每个Channel绑定一个EventLoop不会被改变，因为EventLoopGroup包含少量的EventLoop的Channels，
	很多Channel会共享同一个EventLoop。这意味着一个Channel保持EventLoop繁忙会禁止其他Channel绑定到相同的EventLoop。EventLoop是
	一个事件循环线程，而EventLoopGroup是一个事件集合。

Bootstrap：
	引导是Netty中配置程序的过程，当你需要连接客户端或服务器绑定指定端口时需要使用bootstrap。
	bootstrap有两种类型，一种是用于客户端的Bootstrap，一种用于服务端的ServerBootstrap。
		ServerBootstrap：
			在服务器监听一个端口轮询客户端的Bootstrap是否连接服务器。通常需要调用Bootstrap类的connect()
			方法，但是也可以先调用bind()再调用connect()进行连接，之后使用的Channel保护在bind()返回的
			ChannelFuture中。
			ServerBootstrap使用2个EventLoopGroup(相同的实例),一个ServerBootstrap可以任意有2个channels组，第一
			组包含一个单例ServerChannel，代表持有一个绑定了本地端口的socketl第二组保护所有的Channel，代表服务器
			已接受了的连接。
			Netty 可以使用两个不同的Group，因为服务器程序需要接受很多客户端连接的情况下，一个 EventLoopGroup
			将是程序性能的瓶颈，因为事件循环忙于处理连接请求，没有多余的资源和空闲来处理业务逻辑，最后的结果
			会是很多连接请求超时。若有两EventLoops， 即使在高负载下，所有的连接也都会被接受，因为 EventLoops 
			接受连接不会和哪些已经连接了的处理共享资源。
ChannelInitializer:
	ChannelInitializer是一个特殊的 ChannelHandler，通道被注册到 EventLoop 后就会调用
	ChannelInitializer，并允许将 ChannelHandler 添加到 CHannelPipeline；完成初始化通道后，这个特殊的
	ChannelHandler 初始化器会从 ChannelPipeline 中自动删除。				 
ByteBuf：
	ByteBuf有两个部分：一个用于读，一个用于写。可以按照顺序的读取数据，并且可以跳到开始重新读一遍。
	写入数据到ByteBuf后，写入索引是增加的字节数量。开启读字节后，读取索引增加。

ChannelHandler：
	为了使数据从一端到达另一端，一个或多个CHannelHandler将以某种方式操作数据。这些CHannelHandler会在程序的引导
	阶段被添加ChannelPipeline中，并且被添加的顺序将决定处理数据的顺序。ChannelPipeline的作用是用来管理ChannelHandler
	的一个容器，每个ChannelHandler处理各自的数据，处理完成后将装的数据放到ChannelPipeline中交个下一个ChannelHandler
	继续处理，知道最后一个ChannelHandler处理完成

Channel：
	ChannelPipeline：
		ChannelPipeline是ChannelHandler实例的列表，用于处理或截获通道的接收和发送数据。
		对于每个新的Channel，会创建一个新的ChannelPipeline并附加至通道。一旦链接，Channel和ChannelPipeline之
		间的耦合是永久的。Channel不能附加其他的ChannelPipeline或从CHannelPipeline分离。
		ChannelPipeline的作用可以理解为用来管理ChannleHandler的一个容器，每个ChannelHanndler处理各自
				 的数据，处理完后将转换的数据放到ChannelPipeline中交给下一个ChannelHandler继续处理，直到最后
				 一个ChannelHandler处理完成。	
	ChannelHandlerContext:
		每个ChannelHanndler被添加到ChannelPipeline后，都会创建一个CHannelHandlerContext并与之创建的ChanneHandler
		关联绑定。ChannelHandlerContext允许ChannelHandler与其他的ChannelHandler实现进行交互，这是相同
		ChannelPipeline的一部分。
		一个ChannleHandler绑定的ChannelHandlerContext永远不会改变，所以他的引用缓存起来是安全的。
		ChannelHandlerContext有很多方法，其中一些方法Channel和ChannelPipeline也有，但是有些区别。如果你在Channel
		或者ChannelPipeline实例上调用这些方法，它们的调用会穿过整个pipeline。而在ChannleHandlerContext上调用的同
		样方法，仅仅从当前ChannleHandler开始，走到pipeline中下一个可以处理整个event的ChannlelHandler。
	
当注册一个Channel后，Netty将这个CHannel绑定到一个EventLoop，在Channel的生命周期内总是绑定到一个EventLoop。在Netty IO 操作中，你的程序不需要同步，因为一个指定通道的所有IO
始终由同一个线程来执行	

ByteBuf:写入数据到byteBuf后，写入索引是增加的字节数量。开始读字节后，读取索引增加。知道写入索引和读取索引处理
相同的位置，黩武穷兵完成。
	Heap Buffer(堆缓冲区)：
		最常用的类型是ByteBuf将数据存储在JVM的堆空间，这事通过将数据存储在数组的实现。堆缓冲区可以快速分配，当
		不使用时也可以快速释放。
	Direct Buffer(直接缓冲区)
		直接缓冲区，在堆之外直接分配内存。直接缓冲区不会占用堆空间容量，使用时应该考虑应用程序要使用的最大内存
		容量以及如何限制它。

	一个Netty程序开始与Bootstrap类，Bootstrap类是Netty提供的一个可以通过简单配置来设置或引导程序的一个重要类。Netty中设计了Handlers来处理特定的event和设置Netty中的事件，
从而来处理多个协议和数据。时间可以描述成一个通用的方法，因为你可以自定义一个handler，用来将Object转成byte[]或将byte[]转成Object.
	经常编写一个实现CHannelInboundHandler的类，ChannelInboundHandler是用来接收消息，当有消息过来时，你可以决定如何处理。当程序需要返回消息时可以在CHannelInboundHandler里
write/flush数据。业务逻辑都是在ChannelInboundHandler中来处理的。
	Netty链接客户端或绑定服务器需要知道如何发送或接收消息，这事通过不同类型的handlers来做的，多个Handlers是怎么配置的？Netty提供了ChannelInitializer类用来配置Handlers。
ChannelInitailizer是通过ChannelPipeline来添加ChannelHandler的，如发送和接收消息，这些Handlers将确定发的是什么消息。ChannelIntializer自身也是一个ChannelHandler，在添加完其
他的handlers之后会自动从ChannelPipeline中删除自己。

Reactor
	主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），
	将新创建的SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，
	一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。
	利用主从NIO线程模型，可以解决1个服务端监听线程无法有效处理所有客户端连接的性能不足问题。因此，在Netty的官方demo中，推荐使用该线程模型。
	事实上，Netty的线程模型并非固定不变，通过在启动辅助类中创建不同的EventLoopGroup实例并通过适当的参数配置，就可以支持上述三种Reactor线程模型。正是因为Netty 对Reactor线程模型的支持
	提供了灵活的定制能力，所以可以满足不同业务场景的性能诉求。

Encoder(编码器),Decoders(解码器)
	发送或接收消息后，netty必须将消息数据从一种形式转换另外一种。接收消息后，需要将消息从字节码转成Java对象;发送消息前，需要将java对象转成字节。这种转换一般发生
	在网络程序中，因为网络只能传输字节数据。我已经想好自己的目标了，我要开一家Fate zero的主题餐厅，其名为理想乡，以Excalibur 为logo ！想想就觉得超级帅！









SpringBoot
	@SpringBootApplication是一个组合注解，它的核心功能是由@EnableAutoConfiguration，@EnableAutoConfiguration中关键功能@Import注解导入的配置功能，
	EnableAutoConfigurationImportSelector使用SpringFactoriesLoader.loadFactoryNames方法来扫描具有META-INF/spring.factories文件的jar包，这里用的是
	spring-boot-autoconfigure.jar中spring.factories文件，此文件中声明了有哪些自动配置。打开spring.factories文件下*AutoConfiguration文件，都组合了@Conditional*元注解，



Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。

Reactor模式本质上是一个事件机制，通过一个或一组线程检查事件，发现事件知乎交给另一组事件处理线程执行该事件所对应的
事件处理器(回调)，从而实现高响应的程序。







tomcat

Lifecycle:相当于抽象主题角色，所有的容器类与组件实现类都实现了这个接口。如StandardContext
LifecycleListener:相当于抽象观察者角色,具体的实现类有ContextConfig, HostConfig, EngineConfig类，它们在容器启动时与停止时触发。
LifecycleEvent:生命周期事件，对主题与发生的事件进行封装。
LifecycleSupport:生命周期管理的实用类，提供对观察者的添加，删除及通知观察者的方法。
LifecycleException:生命周期异常类。

1) 请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得
2) Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应
3) Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host
4) Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机）
5) localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context
6) Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为""的Context去处理）
7) path="/wsota"的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet
8) Context匹配到URL PATTERN为*.jsp的servlet，对应于JspServlet类
9) 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法
10)Context把执行完了之后的HttpServletResponse对象返回给Host
11)Host把HttpServletResponse对象返回给Engine
12)Engine把HttpServletResponse对象返回给Connector
13)Connector把HttpServletResponse对象返回给客户browser



bootstrapClassLoader是加载java_home/jre/lib目录下的个别jar包（不是全部）

extClassLoader是加载java_home/jre/lib/ext目录下的jar包

AppClassLoader是加载classpath中指定的jar包

在catalina.properties文件中则common.loader指出了这3个ClassLoader默认的加载路径


#





ConcurrentHashMap

	ConcurrentHash是线程安全的哈希表，是通过“锁分段”来实现的。ConcurrentHashMap中包括了“Segment(锁分段)数组”，每个Segment就是一个哈希表，而且是可重入的互斥锁。
	一、Segment是哈希表表现在Segment包含了"HashEntry数组"，而"HashEntry数组"中每个HashEntry元素是一个单向链表。即Segment是通过链式哈希表。
	二、Segment继承于ReentrantLock，ReentrantLock就是可重入的互斥锁。
		对应ConcurrentHashMap的添加、删除开始前，线程都会获取Segment的互斥锁：操作完毕后，才会释放。而对于读取操作，是通过volatile实现的，hashEntry数组是volatile类型的，
	1、ConcurrentHashMap继承于AbstractMap抽象类，实现ConcurrentMap
	2、Segment是ConcurrentHashMap中的内部类，它就是ConcurrentHashMap中的“锁分段”对应的存储结构。ConcurrentHashMap与Segment是组合关系，1个ConcurrentHashMap对象包含若干个Segment对象。
	3、Segment继承与ReentrantLock类，所以Segment本质是一个可重入的互斥锁
	4、HashEntry也是ConcurrentHashMap的内部类，是单向链表节点，存储着key-value键值对。Segment与HashEntry是组合关系，Segment类中存在HashEntry数组成员，HashEntry数组中的每个HashEntry就是
	   一个单向链表。
	5、对于多线程访问对一个“哈希表对象”竞争资源，Hashtable是通过一把锁来控制并发；而ConcurrentHashMap则将哈希表分成许多片段，对于每个片段分别通过一个互斥锁来控制并发。





linux load
	在Linux进程中，进程分为三种，一种是阻塞的进程、一种是可运行的进程、一种是正在运行的进程
	进程可运行状态时，它处在一个运行队列中，与其他可运行进程争夺CPU时间，系统的load是指正在运行和准备好运行的进程的总数。如现在系统有2个正在运行的进程，3个可运行的进程，那么系统的load
	就是5。




工作遇到什么难题
	稍微想一下，因为之前确实碰到了这个问题，当时做这个项目时，对netty的不过熟悉，把请求的业务逻辑放在work线程池的线程中进行处理，进行压测的时候，
	发现qps总是上不去，后来看了源码之后才发现，由于业务逻辑的处理比较耗时，完全占用了work线程池的资源，导致新的请求一直处于等待状态。
	面试官：那最后是如何解决的？我：最后把处理业务的逻辑封装成一个task提交给一个新建的业务线程池中执行，执行完之后由work线程池执行请求的write事件。


redis
	redis集群
		reids集群没有入口，连接任何节点都可以，内部的节点都是互相通信的。
		如何检测节点健康状态？投票容错，如超过半数节点认为某个节点挂了，那他就是挂了。b发现a节点没有调通，发一个广播通知其他节点询问a节点是否挂了，
		，挂了之后，会将a的从节点替换成主节点。
		什么时候节点挂了？
			所有的redis节点彼此互联(ping-pong机制),内部使用二进制协议优化传输速度和带宽。
			节点的fail是通过集群中超过半数的节点检测失效才生效
			客户端与redis节点直连，不需要中间proxy,客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可
			集群中把所有的物理节点映射到[0-16383]solt上
			reids集群中内置了16384个哈希槽，当需要redis集群中放置一个key-value时，redis先对key使用crc16算法算出一个结果，然后把结果对16384求余数
			，这样每个key都会对应一个编码0-16383之间的哈希槽，redis会根据节点数量大致均等的哈希槽映射不同的节点
			
			如果有一个节点挂了，集群就挂了
			
		节点
		一个redis集群通常由多个节点组成，在刚开始的时候，每个节点都是互相独立的，他们都处于一个只包含自己的集群当中，要组建一个真正可
		工作的集群，必须将各个独立的节点连接起来，构成一个包含多个节点的集群。	
		
		重新分片
			redis集群的重新分片可以将人员数量已经指派给某个节点(源节点)的槽改为指派给另一个节点(目标节点)，并且相关槽所属的键值对也会
			从源节点被移动到目标节点。重新分配操作可以在线进行，集群不需要下线，并且源节点和目标节点哦都可以继续处理命令请求。
			因为一个槽下面可能有很多键值对，所以源节点向目标节点迁移一个槽的过程中，可能会出现这样一种情况：被迁移槽的一部分键值对保存在源节点里面，
			而另一部分键值对则保存在目标节点里面。 
			当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的键恰好就属于正在被迁移的槽（migrating_slots_to数组会保存所以正在迁往其它节点的槽）时： 
				·源节点会先在自己的数据库里面查找指定的键，如果找到的话，就直接执行客户端发送的命令。 
				·如果源节点没能在自己的数据库里面找到指定的键，源节点将向客户端返回一个ASK错误，指引客户端转向正在导入槽的目标节点，并再次发送之前想要执行的命令。
			
		重新分片的实现原理
			1)redis-trib对目标节点发生导入命令，让目标节点准备好从源节点导入属于槽slot的键值对。
			

		
redis主从复制
	主要是通过master server持久化rdb文件实现的。master server 先dump出内存快照文件，然后将rdb文件传送给slave server，slave server根据rdb文件重新
	建立内存表。
	
完全复制过程
	1、slave server启动连接到master server之后，slave server主动发送sync命令给master server
	2、master server接受sync命令后，判断是否有正在内存快照的子进程，如果有则等待其结束，否则fork一个子进程，子进程把内存数据保存为文件，并发送slave server
	3、master server子进程进程做内存快照时，父进程可以继续接收chient端请求写数据，此时父进程将新写的数据放到待发送缓存队列中
	4、slave server接收内存快照文件后，清空内存数据，根据接收的快照文件，重建内存表数据结构
	5、master server把快照文件发送完成后，发送缓存队列中保存的子进程快照期间改变的数据给slave server，slave server做相同的处理，保证数据一致性
	6、master server后续接收的数据，都会通过第一步建立的连接，把数据发送给slave server
部分复制过程
	1、主服务器的复制偏移量和从服务器的复制偏移量
	2、主服务器的复制积压缓冲区，缓冲区是一个固定大小的先进先出队列
	3、服务器的运行Id
	是否适用部分同步的检查方法：
		如果从服务器记录的主服务器id和当前连接的主服务器的id相同，并且从服务器记录的偏移量所指定的数据仍然保存在主服务器的复制流缓存区里面，那么主服务器会向
		从服务器发送断线时缺失的那部分数据，然后复制工作可以开始了。
		
	
rdb快照持久化
	RDB 程序将当前内存中的数据库快照保存到磁盘文件中， 在 Redis 重启动时， RDB 程序可以通过载入 RDB 文件来还原数据库的状态。

	rdb执行持久化是由子进程执行保存操作，该命令不会阻塞服务器。rdb文件是一个经过压缩的二进制文件。

	每隔n分钟或n次些操作后，从内存dump数据形成rdb文件，压缩放在备份目录。
	save 900 1 #刷新快照到硬盘中，必须满足两者要求才会触发，即900秒之后至少有1个关键字变化。
	save 300 10 #必须300秒有10个关键字变化。
	save 60 10000 #必须60秒有10000个关键字变化。
	stop-writes-on-bgsave-error yes #后台存储错误停止写。
	rdbcompression yes #使用lzf压缩rdb文件。
	rdbchecksum yes #存储和加载rdb文件时校验。
	dbfilename dump.rdb #设置文件名。
	dir ./ #设置工作目录，rdb会写入该目录。

aof
	AOF持久化会将被执行的写命令写到AOP文件的末尾，以此来记录数据发生的变化。因此，Redis只要从头到尾重新执行以此AOF文件包含的所有写命令，就
	可以恢复AOF文件所记录的数据集。

	aof后台执行的方式，fork 一个子进程，主进程仍进行服务，子进程执行 AOF 持久化，数据被 dump 到磁盘上。与 RDB 不同的是，后台子进程持久化过程中，
	主进程会记录期间的所有数据变更（主进程还在服务），并存储在 server.aof_rewrite_buf_blocks 中；后台子进程结束后，redis 更新缓存追加到 AOF 
	文件中，是 RDB 持久化所不具备的。
	
	执行操作命令请求会保存到aof缓冲区里面，定期写入并同步aof文件。服务器只要载入并重新执行保证在aof文件中的命令，就可以还
	原数据库本来的状态。再还原会对aof文件重写，产生一个新的aof文件，这个新的aof文件和原有的aof文件保存的数据库状态一样，
	但体积更小。


	在执行重写命令时，redis服务器会维护一个aof重写缓冲区，该缓冲区会在子进程创建新aof文件期间，记录服务器执行的所有写命令
	。当子进程完成创建新aof文件的工作后，服务器会将重写缓冲区中的所有内容追加到新aof文件末尾，使新旧两个aof文件所保存的数据库
	状态一致。最后，服务器用新的aof文件替换旧的aof文件，来完成aof文件重写操作。

	appendonly yes #是否开启 aof日志功能
	
	appendfsync always #没1个命令都立即同步到aof  （安全，速度慢）
	appendfsync everysec #择中方案，每秒写一次
	appendfsync no #写入操作交给操作系统，由操作系统判定缓存大小写入aof （同步率低，速度快）
	auto-aof-rewrite-percentage 100 如果aof重写执行过于频繁，如果执行100个写进行重写文件
	auto-aof-rewrite-min-size 64mb 当aof体积大于64mb，进行重写文件

	no-appendfsync-on-rewrite yes #正在导出rdb快照的过程要不要停止aof

redis事务原理
	http://redisbook.readthedocs.io/en/latest/feature/transaction.html

文件事件：
	redis服务器通过套接字与客户端进行连接，而文件事件就是服务器对套接字操作的抽象。服务器与客户端的通信会产生相应的文件事件，而服务器则通过监听
	并处理这些事件来完成一系列网络通信操作。
事件事件；
	redis服务器中的一些操作需要在给定的时间点执行，而时间事件就是服务器对这类定时操作的抽象。

发送命令请求：
	当用户在客户端输入一个命令请求时，客户端会将这个命令请求转换成协议格式，然后通过连接到服务器的套接字，将协议格式的命令请求发送给服务器
读取命令请求：
	当客户端与服务器之间的连接套接字因为客户端的写入而变得可读时，服务器将调用命令请求处理器来执行以下操作；
		1)度武器套接字中协议格式的命令请求，并将其保存在客户端状态的输入缓冲区里面。
		2)对输入缓冲中的命令请求进行分析，提取出命令请求中包含的命令参数，以及命令参数的个数，然后分别将参数和参数个数保存到客户端状态的
		  argv(数组，存储着 命令、key、value)，argc(数组元素)属性里面。
		3)调用命令执行器，执行客户端指定的命令。
			3.1) 根据客户端状态的argv[0]参数，在命令表中查找参数指定的命令，并将找到的命令保存到客户端状态的cmd属性里面。
				 命令表是一个字典，字典的键是一个个命令名称，如"set、get、del"；而字典的值这是一个rediCommand结构，redisCommand
				 记录的是Redis命令的实现信息。
			3.2) 执行预备操作
					3.2.1)检查客户端状态的cmd指针是否指向null，为null表找不到相应的命令实现
					3.2.2)根据客户端cmd属性执行的redisCommand结构arity(如set要求 set name value，arity值为3，则必须有三个参数)属性，
						  检查命令请求所给定的参数个数是否正确。
			3.3)调用命令的实现函数
					被调用的命令实现函数会执行指定的操作，并产生相应的命令回复，这些回复会被保存在客户端状态的输入缓区里面(buf或reply),
					之后实现函数还会为客户端的套接字关联命令回复处理器，这个处理器负责将命令返回给客户端。
			3.4)执行后续操作
				 aof持久化、慢查询日志
			3.5)将命令回复发送给客户端
				 命令实现函数会将命令回复保存到客户端的输出缓冲区里面，并未客户端的套接字关联命令回复处理器，当客户端套接字变为可写状态
				 时，服务器会执行命令回复处理器，将保存在客户端输出缓冲区中的命令回复给客户端。当命令回复发送完成后，回复处理器会情况客
				 户端状态的输出缓冲区，为处理下一个命令请求做好准备。

主从复制
	当客户端向服务器发生slaveof命令，要求从服务器复制主服务器时，从服务器首先需要执行同步操作
	从服务器对主服务器的同步操作需要通过向主服务器发送sync命令来完成
		1)从服务器向主服务器发送sync命令
		2)收到sync命令的主服务器执行bgsave命令，在后台生产一个rdb文件，并使用一个缓冲区记录从现在开始执行的所有写命令。
		3)当主服务器的bgsave命令执行完成时，主服务器会将bgsave命令生成的rdb文件发送给从服务器，从服务器接收并载入这个
		  rdb文件，将自己的数据库状态更新至主服务器执行bgsave命令时的数据库状态。
		4)主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务
		  器数据库当前所处的状态。
	复制积压
		当主从复制时，从服务器断线，主从都会记录偏移量，当从服务器重新连接时，将偏移量发送主服务器，主服务将偏移量之后
		的数据发送给从服务器，如果从服务发送的偏移量在主服务不存在，则需重新传输rdb文件，复制积压缓冲区大小1M

每当我们在redis的数据库创建一个新键值对，至少会创建2个对象，分别用于键对象、值对象。		

字符串对象：字符串的编码可以是int、raw或者embstr。
	如：
		set number 10086 编码为int
		set str "xxxxx" 编码为embstr
		stt str "xxx...64位" 编码为raw
	如果字符串对象保存的是一个字符串，且长度大于32字节，那么字符串对象将使用简单动态字符串(SDS)保存这个字符串，
	使用raw编码。如果字符串长度小于32字节，字符串编码为embstr。
	embstr编码是专用于保存短字符串的一种优化，和raw都一样，使用redisObject和sdshdr结构表示字符串对象，但raw编码
	会调用两次内存分配函数来分别创建redisObject机构和sdshdr结构，而embstr编码则只调用一次内存分配函数来分配一块
	连续内存空间。
列表对象：列表对象的编码可以是ziplist或linkedlist。
	使用ziplist编码满足以下，以下条件是可以在配置文件修改的。不满足使用linkedlist。
		1)元素长度小于64字节
		2)元素数量小于512个。
哈希对象：哈希对象的编码可以是ziplist或者hashtable
	ziplist编码，同一个键值对两个节点总是紧挨着，键在前，值在后。
	hashtable编码，键、值各有一个字符串对象。
		如:
			StringObject(age) ->  StringObject(18)
			StringObject(name) -> StringObject(张三)
	使用ziplist编码满足以下，以下条件是可以在配置文件修改的。不满足使用hashtable。
		1)元素长度小于64字节
		2)元素数量小于512个。
集合对象：集合对象的编码可以是intset(整数集合)或者hashtable。
	intset编码，邀请集合对象所以元素都是整数。
	hashtable编码，字典的每个键都是一个字符串对象且包含一个集合元素，字典的值则都被设置为null;
	使用intset编码满足以下，以下条件是可以在配置文件修改的。不满足使用hashtable。
		1)集合元素都是整数。
		2)元素数量小于512个。	
有序集合对象：有序集合的编码可以是ziplist或者skiplist。
	ziplist编码，每个集合与酸奶使用两个紧挨在一起的压缩列表节点来保存，第一个是元素成员，第二个是元素值。
				压缩列表内的集合元素按元素值从小到大进行排序。
	skiplist编码，跳跃表按元素值从小到大排序，每个跳跃表节点都保存了一个集合元素。	

redis三种过期策略
	定时删除
		含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除

	惰性删除
		含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。
	定期删除
		含义：每隔一段时间执行一次删除过期key操作
	
nginx 
	
	
	gzip 
		gzip on|off; #是否开启gzip
		gzip_buffers 32 4K|16 8K #缓冲(压缩在内存中缓冲几块，每块多大，推荐 32 4)
		gzip_comp_level[1-9] 压缩级别(级别越高,压的越小，越浪费CPU资源)，推荐6
		gzip_disable 正则匹配UA  什么样的URL不进行gzip
		gzip_min_length 200 开始压缩的最小长度 推荐200
		gzip_proxied 设置请求代理服务器，该如何缓冲内容
		gzip_type text/plain application/xml  那些类型文件进行压缩 如txt,xml,html
		gzip_vary on|off 是否传输gzip压缩标志

	
	正则匹配
		localtion ~ image { //url包含 image
		}

		localtion ~* image { //不区分大小写
		}






















	
	



	