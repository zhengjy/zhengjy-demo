Lucene:
	文档：索引与搜索的主要数据载体，它包含一个或多个字段，存放将要写入索引或将从所有索引处理的数据。
	字段：文档的一个片段，它包括两个部分：字段的名称和内容。
	词项：词项在字段中的一次出现，包括词项的文本、开始和结束的位移以及类型。

	Lucene将写入索引的所有信息组织成一种名为倒排序索引的结构。该结构是一种将词项映射到文档的数据结构。
		每个文档字段都对应着一个倒排序索引。	
		倒排序索引存储结构：
			ElasticSearch Server （文档1）
			MasteringElasticSearch（文档2）
			Apache solr 4 Cookbook（文档3）
			词项				计数		文档
			Apache				1			3
			Cookbook			1			3
			ElasticSearch		2			1,2
			Mastering 			1			2
			Server 				1			1
			Solr				1			3
	段：
		每个索引由多个段组成(segment)组成，每个段只会被创建一次但会被查询多次。索引期间，段经创建就不会在修改。
	段合并：
		多个段会在一个叫做段合并的阶段被合并在一起，Lucene的内在机制决定在某个适合执行，合并后段的数量更少，但是更大。段合并非常耗IO/CPU。

	转换倒排序索引：
		文本分析由分析器来执行，分析器由分词器、过滤器和字符映射器组成。
			分词器：
				分词器用来将文本切割成词条，其中携带各种额外的信息的词项，这些信息包括：词项在原始文本中的位置、词项的长度。分词器的工作成果称为
				词条流，因为这些词条被一个接一个推送给过滤器处理。
			过滤器：
				过滤器额外可选，可以为0-n个，用于处理词条流中的词条。它可以移除、修改词条流中的词条，甚至可以创造新的词条。
				自带的过滤器：
				1)小写过滤
				2)ASCII过滤器：移除词条中所有非ASCII字符
				3)同义词过滤器：根据同义词规则，将一个词条转换为另外一个词条
				4)多语言词干还原过滤器

elasticSearch
		关系数据库     ⇒ 数据库 ⇒ 表    ⇒ 行    ⇒ 列(Columns)

		Elasticsearch  ⇒ 索引(Index)   ⇒ 类型(type)  ⇒ 文档(Docments)  ⇒ 字段(Fields)  
		
	索引：
		es将数据存储在一个或多个索引中。在sql领域中索引就像数据库。
		索引实际上是指向一个或多个物理分片的逻辑命名空间。一个分片是底层的工作单元，它仅保存了全部数据的一部分。
	文档：文档是es中主要的实体，文档由字段构成，每个字段有它的字段名以及一个或多个字段值。文档之间可能有各自不同的字段集合，且文档并没有固定的
			模式或强制的结构。
	映射：所有文档在写入索引前都需要进行分析。
	类型：es中每个文档都与之对应的类型定义。允许用户在一个索引中存储多种文档类型，并为不同文档类型提供不同的映射。
	节点：单个es服务实例称为节点。
	集群：多个节点协同处理，所有这些节点组成的系统称为集群。
	分片：集群允许系统存储的数据总量超过单机容量。为了满足这个需求，es将数据散步到多个物理lucene索引上。这些Lucene索引称为分片。
	副本：副本解决了访问压力过大时单机无法处理所有请求问题。即为每个分片创建冗余的副本。

	es工作流程：
		启动过程：
			当es节点启动时，它使用广播技术来发现同一个集群中的其他节点(关键是配置文件中的集群名称)并与他们连接。见面
			集群中会有一个节点被选为管理节点。该节点负责集群的状态管理以及在集群拓扑变化时作出反应，分发索引分片至集群的相应节点上。
			管理节点读取集群的状态信息，并在必要时恢复出来。在该阶段，管理节点会检查所有索引分片并决定哪些分片将用于主分片。然后整个
			集群进入黄色状态。这时集群可以执行查询，但是系统的吞吐量以及各种可能的状态是未知的(主分片已经分配出去了，而副本没有)，
			因而接下来就是寻找到冗余的分片并且用作副本。如果某个主分片的副本数量过少，管理节点将决定基于某个主分片创建分片和副本。如果
			顺利，集群进入绿色状态(主分片和副本均匀分片好)。
		故障检测：
			es集群管理节点会监控所有可用节点，检查它们是否正在工作。如果任何节点在预期时间没有响应，则认为该节点已经断开，然后启动错误
			处理过程。
			如果是三个节点的集群，即包含一个管理节点，两个数据节点。管理节点会发送ping请求至其他节点，然后等待响应，如果没有响应，则该
			节点会从集群中移除。
	
	es建索引操作只会发生在主分片上。当把一个索引请求发送到某个节点，如果该节点没有对应的主分片或者只有副本，那么请求会被转发到拥有正确的
	主分片的节点。
	es查询分为两个阶段：分散阶段、合并阶段
		分散阶段：将query分发到包含相关文档的多个分片中取执行查询。
		合并阶段：从众多分片中收集返回结果，然后对它们进行合并、排序、后续处理，返回给客户端。
	
	分布式文档存储：
		路由一个文档到分片：
			es在创建索引的时候就确定好分片数量并且永远不会改变这个数量。
			shard = hash(routing) % number_of_primary_shards
			routing:是一个可变值，默认是文档的id
			number_of_primary_shards:主分片的数量
			hash(routing) % number_of_primary_shards在 0-number_of_primary_shards之间的余数，就是寻求文档所在分片的位置。
		主分片和副本均匀分片如何交互：
			一个请求可以发送到集群中任意一个节点。每个节点都知道集群中任意一个文档的位置，所以可以直接将请求转发需要的节点上。
			当发送请求时，内部实现了负载均衡，可以实现轮询访问集群中的所有节点。
		新建、索引和删除文档：
			客户端发个删除文档请求倒es的master主节点，主节点会找到通过_id找到归属的主分片节点，主分片执行成功后，会同步到副分片，一旦
			所有副分片都报告成功，会通知master主节点master主节点再返回客户端成功。
		多文档模式：
			多文档模式类似单文档模式。master节点知道每个文档存储在那个分片中。将多个文档请求分解为每个分片的多文档请求，并且将这些请求并发
			转发到每个参与节点。master主节点收到每个节点的应答，将每个节点的响应收集整成单响应返回给客户端。
	

	segment(段)：
		es中每一个段都是一个倒排序索引。
		一个Lucene索引在es中称为分片，一个es索引是分片的集合。当es在搜索的时候，他发送查询到每一个属于索引的分片，然后合并每个分片的结果到一个
		全局的结果集。
		新收到的数据写入新的索引文件里。Lucene把每次生成的倒排序索引，叫做一个段。然后另外使用一个commint文件，记录索引内的所有segment。
		而生成sentiment的数据来源，则是内存中的Buffer。
			动态更新过程如下：
				1)当前磁盘有segment可用，同时有一个commit文件记录当前的segment
				2)新收到的数据进入内存buffer
				3)buffer刷到磁盘，生成新的segment,commit文件同步更新。
	
	分片的过度分片：
		分片处理是将一个索引分割成若干个更小的索引过程，从而能够在同一个集群的不同节点上散步它们。在查询的时候，结果是索引中每个分片返回结果的汇总。
		es必须在创建索引时就指定好需要的分片数量。
		更多的分片意味着每个较小的lucene索引上执行的操作会更快。如果将查询分散成对每个分片请求，然后合并结果，也是有代价的。
	
	副本：
		副本过多的缺点，各个分片的副本占用了额外的存储空间，主分片及副本之间的数据拷贝也存在时间开销。
	
	路由：
		路由确保了在索引时拥有相同路由值的文档会索引到相同的分片上，但一个给定的分片上可以有很多拥有不同路由值的文档。
		
	搜索：
		一种复杂的执行模型，因为不知道查询会中那些文档：这些文档可能在集群的任何分片上。
		查询阶段：
			在初始查询阶段时，查询会广播到索引中每个分片。每个分片在本地执行搜索并构建成一个匹配文档的优先队列。一个优先队列是一个有top-n的有序列表。
			查询分为3个阶段：
				1)客户端发送一个search请求到节点A，节点A会创建一个大小为from + size 的空优先队列
				2)节点A将查询请求转发到索引的每个分片中。每个分片在本地执行查询并添加结果到大小为from+size的本地有序优先队列中。
				3)每个分片返回各自优先队列中的所有文档的id和排序值给节点A，它合并这些值到自己的优先队列中产生一个全局排序后的结果列表。
		取回阶段：
			查询阶段标识哪些文档满足搜索请求，此阶段是要取回文档。
			取回阶段分为3个阶段：
				1)节点A辨别出哪些文档需要被取回并向相关的分片提交多个GET请求。
				2)每个分片加载并丰富文档，接着返回给节点A。
				3)一旦所有文档都被取回了，协调节点返回给客户端。
	
	游标：
		ES的搜索是分2个阶段进行的，即Query阶段和Fetch阶段。  Query阶段比较轻量级，通过查询倒排索引，获取满足查询结果的文档ID列表。  而Fetch阶段比较重，需要将每个shard的结果取回，
		在协调结点进行全局排序。  通过From+size这种方式分批获取数据的时候，随着from加大，需要全局排序并丢弃的结果数量随之上升，性能越来越差。
		而Scroll查询，先做轻量级的Query阶段以后，免去了繁重的全局排序过程。 它只是将查询结果集，也就是doc id列表保留在一个上下文里， 之后每次分批取回的时候，只需根据设置的size，
		在每个shard内部按照一定顺序（默认doc_id续)， 取回这个size数量的文档即可。 
		由此也可以看出scroll不适合支持那种实时的和用户交互的前端分页工作，其主要用途用于从ES集群分批拉取大量结果集的情况，一般都是offline的应用场景。  
		比如需要将非常大的结果集拉取出来，存放到其他系统处理，或者需要做大索引的reindex等等。
	
	分片内部原理：
		使文档可被搜索:
			es采用倒排序索引存储。保存每个词项出现过的文档总数，在对应的文档中一个具体词项出现的总次数，词项在文档中的顺序，每个文档的长度等等。
		不变性：
			倒排序索引被写入磁盘后，不可变，为实现倒排序索引的更新，通过更多的索引实现。通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排序索引。
			每个倒排序索引都会被轮流查询到从最早的开始，查询完后再对结果进行合并。
		动态更新索引：
			
			新文档首先被添加到内存索引缓存中，然后写入一个基于磁盘的段。
			
			逐段搜索:
				1)新文档被收集到内存索引缓存
				2)每秒缓存被提交
					2.1)一个新的段-一个追加的倒排序索引-被写入磁盘
					2.2)一个新的包含新段名字的提交点被写入磁盘
					2.3)磁盘进行 同步-所有在文件系统缓存中等待的写入都刷新到磁盘。
				3)新的段被开启，让它包含的文档可以被搜索
				4)内存缓存被清空，等待接收新的文档。
			
			1)一个文件被索引后，会被添加到内存缓冲区，并且追加到translog。
			2)分片每秒被刷新一次:
				2.1)这些内存缓冲区的文档被写入到一个新的段，且没有进行fysnc操作
				2.2)这个段被打开，使其可被搜索
				2.3)内存缓冲区被清空，translog文件保留。
			3)这个进程继续工作，更多的文档被添加到内存缓冲区和translog中。
			4)每隔一段时间-translog文件越来越大，索引被刷新;一个新的translog被创建，并且全量提交被执行
				4.1)所有在内存缓冲区的文档都被写入一个新的段。
				4.2)缓冲区被清空。
				4.3)一个提交点被写入硬盘。
				4.4)文件系统缓存通过 fsync 被刷新（flush）。
				4.5)老的 translog 被删除。
			
		为什么搜索是 近 实时的？
			
		
		为什么文档的 CRUD (创建-读取-更新-删除) 操作是 实时 的?
		Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据?
		为什么删除文档不会立刻释放空间？
		refresh, flush, 和 optimize API 都做了什么, 你什么情况下应该是用他们？
	
	段合并：
		es自动刷新流程会每秒会创建一个新的段，这样会导致短时间内的段数量暴增。而且段数目太多会带来麻烦，因为每个段都会消耗文件句柄、内存和cpu运行周期。
		更重要是因为每个搜索请求都必须轮流检查每个段；所以段越多，搜索越慢。
		es通过后台进行段合并来解决这问题。小的段合并大的段，然后这些大的段再被合并到更大的段。
		段合并的时候会将那些旧的已删除文档从系统中清除。被删除的文档不会被拷贝到新的大段中。
		
		段合并步骤：
			1、当索引的时候，刷新操作会创建新的段并将段打开以供搜索。
			2、合并进程选择一小部分大小相似的段，并且在后台将他们合并更大的段中。这并不会中断索引和搜索。
			3、合并结束，老的段被删除
				3.1)新的段被刷新到磁盘，写入一个包含新段且排除旧的较小段的新提交点。
				3.2)新的段被打开用来搜索。
				3.3)老的段被删除。
	
	
	文档评分
	查询改写
		前缀查询范围
	二次评分
	批量操作索引
	过滤器
	切面过滤器
	数据处理、文本分析、范例的使用
	索引合并、段合并策略
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	