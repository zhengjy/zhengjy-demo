kafka:
​	kafka是一种分布式的，基于发布/订阅的消息系统。kafka对消息保存时根据Topic进行分类，发送消息者成为Producer，消息接受者为Consumer，此为kafka集群有多个kafka实例组成，
​	每个实例(server)成为broker,无论是kafka集群，还是producer和consumer都依赖zookeeper来保证系统可用性集群保存一些meta信息。
​		主要设计目标为：
​		1)以时间复杂度为O(1)的方式提供消息持久化功能，即使对TB以上的数据也能保证常数(数值不变的常量)时间复杂度的访问
​		2)高吞吐率，即使在非常廉价的机器也能做到单机支持每秒100K条以上消息传输
​		3)支持kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输
​		4)同时支持离线数据处理和实时数据处理

	topics：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。一个topics可以认为是一类消息，每个topics将被分为多个partition(区),
	每个partition在存储层面是append log文件。任何发布到此parition的消息都会被直接追加到log文件
	的尾部，每条消息在文件中的位置成为offset(偏移量),offset为一个long型数字，他是唯一标记一条信息。kafka并没有提供其他额外的索引机制来存储offset,因为kafka中几乎不允许
	对消息进行”随机读写“.


dubbo远程调用协议：
​	REST(HTTP+JSON/XML) 性能高
​	RPS(TCP+Hessian 2进制序列化) 默认

启动提供者注册zk,消费者订阅服务，消费者，建立链接，调用接口，将参数序列化传给提供者，提供者反序列化代理执行调用方法，在序列化出去传给消费者，消费者在反序列化。	
​	
本地暴露和远程暴露	
​	在dubbo中我们一个服务可能既是Provider,又是Consumer,因此就存在他自己调用自己服务的情况,如果再通过网络去访问,那自然是舍近求远,因此他是有本地暴露服务的这个设计.
​	本地暴露是暴露在JVM中,不需要网络通信.
​	远程暴露是将ip,端口等信息暴露给远程客户端,调用时需要网络通信.
​	
dubbo协议：
​	dubbo缺省协议采用单一长链接和NIO异步通讯，适用于小数据量大并发的调用，以及服务消费者机器数远大于服务提供者机器数的情况。
​	缺省协议，使用基于mina1.1.7+hessian3.2.1的tbremoting交互。
​		连接个数：单连接
​		连接方式：长连接
​		传输协议：TCP
​		传输方式：NIO异步传输
​		序列化：Hessian二进制序列化
​		适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。
​		适用场景：常规远程服务方法调用
RMI协议：
​	rmi协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式
​	Java标准的远程调用协议。
​		连接个数：多连接
​		连接方式：短连接
​		传输协议：TCP
​		传输方式：同步传输
​		序列化：Java标准二进制序列化
​		适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。
​		适用场景：常规远程服务方法调用，与原生RMI服务互操作
hessian协议：
​	Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现
​	基于Hessian的远程调用协议。
​		连接个数：多连接
​		连接方式：短连接
​		传输协议：HTTP
​		传输方式：同步传输
​		序列化：Hessian二进制序列化
​		适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。
​		适用场景：页面传输，文件传输，或与原生hessian服务互操作
http协议:
​	采用Spring的HttpInvoker实现
​	基于http表单的远程调用协议。
​		连接个数：多连接
​		连接方式：短连接
​		传输协议：HTTP
​		传输方式：同步传输
​		序列化：表单序列化（JSON）
​		适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。
​		适用场景：需同时给应用程序和浏览器JS使用的服务。

dubbo节点：
​	Provider：暴露服务的服务提供方。
​	Consumer：调用远程服务的服务消费方。
​	Register：服务注册与发现的注册中心。
​	Monitor：统计服务调用次调和调用时间的监控中心。
​	Container：服务运行容器。

dubbo调用关系：
​	1、服务器启动容器负责启动、加载、运行服务提供者。
​	2、服务提供者在启动时，向注册中心注册自己提供的服务。
​	3、服务消费者在启动时，向注册中心订阅自己所需的服务。
​	4、注册中心返回提供者地址列表给消费者，如有变更，注册中心将基于长连接推送变更数据给消费者。
​	5、服务消费者，从提供者地址列表中，基于软件负载均衡算法，选一台提供者进行调用，如果调用失败，在调用另一台调用。
​	6、服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。
​	服务提供方发布服务到服务注册中心
​	服务消费方从服务注册中心订阅服务
​	服务消费方调用已注册的可用服务

dubbo应用执行流程：
​	1、服务提供者启动，根据协议信息绑定到配置的IP和端口上，如果已有服务绑定相同的IP和端口则跳过
​	2、注册服务信息至注册中心
​	3、客户端启动，根据接口和协议信息订阅注册中心订阅中注册的服务，注册中心将存活的服务地址通知到客户端，当有服务信息变更时客户端可以通过定时
通知得到变更信息
​	4、在客户端需要调用服务时，从内存中拿到上次通知的所有存活地址，根据路由信息和负载均衡选择最终调用的服务地址，发起调用
​	5、通过filter分别在客户端发送请求前和服务端收到请求后，通过异步记录一些需要的信息传递到monitor做监控

dubbo负载均衡：
​	1、Random,随机,按权重配置随机访问概率，调用量越大分配越均匀，默认是这种方式。
​	2、RoundRobin，轮询，按权重设置轮询比例，如果存在较慢的机器容易在这台机器的请求阻塞越多
​	3、LeastActive，最少活跃调用数，不支持权重，只能根据自动识别的活跃数分配，不能灵活调配
​	4、ConsistentHash，一致性hash,对相同参数的请求路由到一个服务提供者上，如果有类似灰度发布需求可采用
​	dubbo的负载均衡机制是在客户端调用时通过内存中的服务信息及配置的负载均衡策略选择，如果对自己的系统没有一个全面的认知，建议采用默认random

其他了解：
​	1.<dubbo:service/> 服务配置，用于暴露一个服务，定义服务的元信息，一个服务可以用多个协议暴露，一个服务也可以注册到多个注册中心。
​	2.可通过注解提供服务和调用。
​	3.Dubbo缺省会在启动时检查依赖的服务是否可用，不可用时会抛出异常，阻止Spring初始化完成，以便上线时，能及早发现问题，默认check=true;
​		关闭所有服务的启动时检查：(没有提供者时报错)<dubbo:consumer check="false" />
​	4.在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连。自动加载${user.home}/dubbo-resolve.properties文件，不需要配置
​	5.可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。
​		<dubbo:registry address="10.20.153.10:9090" register="false" />
​	6.多协议暴露服务
​		<dubbo:protocol name="dubbo" port="20880" />
​		<dubbo:protocol name="hessian" port="8080" />
​	7.多注册中心注册
​		<dubbo:registry id="hangzhouRegistry" address="10.20.141.150:9090" />
​		<dubbo:registry id="qingdaoRegistry" address="10.20.141.151:9010" default="false" />
dubbo过滤器：


1、注册标签解析器（自定义的dubbo标签），生成对应的BeanDefinition交给spring管理
2、验证所需要的组件是否已经准备好如(consumer、provider)

dubbo源码解析：
​	使用dubbo.xsd文件来定义dubbo相关的元素及属性;DubboNamespaceHanndler来像spring容器注册dubbo的元素解析器;DubboBeanDefinitionParser用来解析具体的dubbo元素。
​	
	服务提供者暴露一个服务的详细过程:
		再ServiceConfig.export()或ReferenceConfig.get()初始化时，将Bean对象转换URL格式，所有Bean熟悉转换URL的参数。然后将URL传给
		协议扩展点，基于扩展点的扩展点自适应机制，根据URL的协议头，进行不同的服务暴露或引用。
		
		首先ServiceConfig类拿到对外提供服务的实际类ref(如：HelloWorldImpl)，然后通过ProxyFactory类getInvoker方法使用ref生成一个
		AbstractProxyInvoker实例，到这一步就完成具体服务到Invoker的转换。接下来就是Invoker转到Exporter的过程。Dubbo协议的Invoker
		转为Exporter发生再DubboProtocol类的exportf方法，它主要是打开socket监听服务，并接收客户端发来的各种请求。
	
	服务消费者消费一个服务的详细过程：
		首先ReferenceConfig类的init方法调用Protocol的refer方法生成Invoker实例，接下来Invoker转换位客户端需要的接口如(HellpWorld)

dubbo设计@adaptive注解的原因
​	为什么要设计adaptive？注解在类上和注解在方法上的区别？
​	adaptive设计的目的是为了识别固定已知类和扩展未知类。
​	1.注解在类上：代表人工实现，实现一个装饰类（设计模式中的装饰模式），它主要作用于固定已知类，
​	目前整个系统只有2个，AdaptiveCompiler、AdaptiveExtensionFactory。
​	a.为什么AdaptiveCompiler这个类是固定已知的？因为整个框架仅支持Javassist和JdkCompiler。
​	a.为什么AdaptiveExtensionFactory这个类是固定已知的？因为整个框架仅支持2个objFactory,一个是spi,另一个是spring
​	2.注解在方法上：代表自动生成和编译一个动态的Adpative类，它主要是用于SPI，因为spi的类是不固定、未知的扩展类，所以设计了动态$Adaptive类.
​	例如 Protocol的spi类有 injvm dubbo registry filter listener等等 很多扩展未知类，
​	它设计了Protocol$Adaptive的类，通过ExtensionLoader.getExtensionLoader(Protocol.class).getExtension(spi类);来提取对象

RocketMQ:
​	RocketMQ所有消息都是持久化硬盘的。
​	p发送第一条消息给MQ。回调本地事物执行，保证MQ一定有数据，本地事物一定执行的。根据本地事物执行成功失败返回一个状态，执行成功的话就发送给MQ，MQ标识可以消费。
​	c就可以消费这个mq。
​	RocketMQ第一阶段发送Prepared(事先准备好的)消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址
​	去访问消息，并修改状态。如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，如果发现了Prepared消息，
​	他会向消息发送者确认，通过RocketMQ策略来决定是回滚还是继续发送确认消息。


Zookeeper
​	使用Zookeeper的临时性ZNode来存放服务提供者的RMI地址，一旦与服务提供者的Session中断，自动清除ZNode。
​	服务消费者去监听ZNode，一旦发现Znode的数据有变化，就会从新获取一份有效数据的拷贝。
​	服务消费者在创建的时候连接Zookeeper，同时监听/register节点的NodeChildrenChanage事件，一旦/register节点的子节点变化，就需要重写获取最新的子节点。


分布式锁，幂等性、一致性
​	1)使用redis的setnx()、expire()方法，用于分布式锁
​		1. setnx(lockkey, 1)  如果返回0，则说明占位失败；如果返回1，则说明占位成功
​		2. expire()命令对lockkey设置超时时间，为的是避免死锁问题。
​		3. 执行完业务代码后，可以通过delete命令删除key。
​		  这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。比如，如果在第一步setnx执行成功后，在expire()命令执行成
​		  功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用redis的setnx()、get()和getset()方法来实现分布式锁。   
​	2)基于数据库表做乐观锁，用于分布式锁。
​	3)队列处理

#### 分布式事物

​	1、更新数据库
​	2、更新成功发送消息，更新失败则不发送
​	3、发送消息失败则回滚

##### 	本地消息表实现：

​		核心思想是将分布式事务拆分为本地事务进行处理	

​		基本的思路：

​			消息生产方，需要额外建立一个消息表，并记录消息发送状态。消息表和业务数据表要在一个事务提交，他们是在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送

​			消息消费方，需要处理这个消息，并且完成自己的业务。此时如果本地事务处理成功，表明已经处理成功，如果处理失败，则会重试执行。如果是业务上的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。

​			生产方和消费方定时扫描本地消息表，把还没处理完成或失败的消息再发送一遍。

​		优点：一种经典的实现，避免了分布式事务，实现了最终一致性。

​		缺点：消息表会和耦合到业务系统中。

##### 	MQ事务消息：

​		RocketMQ，他们支持事务消息的方式也是类似于采用的二阶段提交。

​		第一阶段Prepared消息，会拿到消息地址。第二阶段执行本地事务，第三阶段通过拿第一阶段地址去访问消息，并修改状态。

​		业务方法内想要消息队列提交两次请求，一次发送消息一次确认消息。如果确认消息发送失败RocketMQ会定期扫描消息集群的事务消息，这时候发现Prepared消息，会向消息发送者确认，所以生产方需要实现一个check接口，RocketMQ会根据发送端配置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或失败。

​	![1554086754(1)](E:\develop\git_workspase\zhengjy-demo\zhengjy-demo-deploy\src\main\resources\file\md_img\1554086754(1).png)
RocketMQ分布式事物：
​	1、将扣费消息先注册到zk上，状态Init
​	2、执行更新数据库，
​	3、数据库更新成功，变更消息状态，exe
​	4、如果变更消息状态失败，rocketMQ会每分钟请求一次，注册到zk上的消息状态为init，询问是否作废还是重发



dubbo负载均衡
​	轮询算法
​		每一次把来自用户的请求轮流分配给内部中的服务器。如：从1开始，一直到N(其中，N是内部服务器的总个数)，然后重新开始循环。
​		优点：简洁性，无需记录当前所有连接状态，它是一种无状态调度。
​		缺点：轮询调用是假设所有服务器的处理性能相同，不关系每台服务器的连接数和响应速度。当请求服务间隔时间变化比较大时，轮询调度算法容易导致服务器间的负载不平衡。
​	一致性Hash
​		相同参数的请求总是发到同一个提供者。
​	随机算法
​		按权重设置随机概率
​	最少活跃调用数
​		相同活跃数的随机，活跃数指调用前后计数差。
​		使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。
​		
dubbo集群容错
​	Failover Cluster模式
​		这种模式是Dubbo集群容错默认的模式选择，调用失败时，会自动切换，重新尝试调用其他节点上可用的服务。
​	Failfast Cluster模式
​		快速失败模式，调用只执行一次，失败则立即报错。
​	Failback Cluster模式
​		配置值为failback。失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
​	Forking Cluster模式
​		配置值为forking。并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。

一致性哈希：
​	 1.首先求出每个节点(机器名或者是IP地址)的哈希值，并将其分配到一个圆环区间上（这里取0-2^32）。
​     2.求出需要存储对象的哈希值，也将其分配到这个圆环上。
​     3.从对象映射到的位置开始顺时针查找，将对象保存到找到的第一个节点上。
​	 考虑到哈希算法在node较少的情况下，改变node数会带来巨大的数据迁移。为了解决这种情况，一致性哈希引入了“虚拟节点”的概念： 
​	 “虚拟节点”是实际节点在环形空间的复制品，一个实际节点对应了若干个“虚拟节点”，“虚拟节点”在哈希空间中以哈希值排列。
​	 
​	 
服务器性能压测：
​	TCP网络参数调优
​		标识一个TCP连接需要四个元素组成(源(客户端)ip、port,目标(服务端)ip、port。)。一台服务器一般有2的48次方(65536)个端口，
​		即客户端做压测时受限制最多只能打开2*48次方个端口。服务器则没有限制，但是服务端会有"文件句柄(打开文件的数量)的限制"。
​		客户端：
​			端口的范围扩大，/proc/sys/net/ipv4/ip_local_port_range
​		服务端：
​			文件句柄的增加，/etc/security/limits.conf
​		

 由于TCP是全双工的，因此关闭连接必须在两个方向上分别进行。首先发起关闭的一方为主动关闭方，另一方为被动关闭方。很多人都会在这里晕掉，
 实际上四次挥手比三次握手还简单。四次挥手简单地分为三个过程：
​		过程一.主动关闭方发送FIN，被动关闭方收到后发送该FIN的ACK；
​		过程二.被动关闭方发送FIN，主动关闭方收到后发送该FIN的ACK；
​		过程三.被动关闭方收到ACK。
以上三步下来，圆圈就闭合了！也就是说，在过程三后，被动关闭方就可以100%确认连接已经关闭，因此它便可以直接进入CLOSE状态了，
然而主动关闭的一方，它无法确定最后的那个发给被动关闭方的ACK是否已经被收到，据TCP协议规范，不对ACK进行ACK，因此它不可能再收到被动关闭方的
任何数据了，因此在这里就陷入了僵局，TCP连接的主动关闭方如何来保证圆圈的闭合？这里，协议外的东西起作用了，和STP(Spanning tree)依靠各类超
时值来收敛一样，IP也有一个超时值，即MSL。
主动关闭一方等待MSL时间再释放连接，这个状态就是TIME_WAIT。对于被动关闭的一方，发出FIN之后就处在了LAST_ACK状态了，既然已经发出FIN了，缺的无
非也就是个ACK，连接本身其实已经关闭了，因此被动关闭的一方就没有TIME_WAIT状态。
​	
​	


es
​	一个分布式的实时文档存储，每个字段都可以被索引搜索
​	一个分布式实时分析搜索引擎
​	能胜任上百个服务节点的扩展，并支持PB级别的结构化或者非结构化数据



分布式主存复制保证一致性：
​	1)引用一个中间件，记录某条记录发生改变，如果有读操作会把他转到主服务来处理，因为从服务器可能还没同步过来。同步完成删除这条记录。
​	2)读写都路由到主库，从库只要主库挂了才用来升级到主库
​	
redis如何保证分布式锁一致性：
​	setnx resource_name my_random_value 30000	
​	

	获取当前时间 -> 依次像N个节点获取锁 -> 计算获取锁耗时多长时间 -> (当前时间 - 获取N个节点时间) < 超时时间(30) & 成功节点 >= N/2+1  ->  重新计算有效时间,要减去 第3、4步的耗时，set有效时间
	
	1)获取当前时间
	2)依次次向N个节点获取锁
	3)计算向N个节点获取锁耗时多少时间
	4)(当前时间 - 获取N个节点时间) < 超时时间(30) && 成功节点 >= N/2+1
	5)重新计算过期时间，当前时间 - 3、4步的耗时，set过期时间 
	private boolean getLock(){
	    long expire = 30000;
	    //1、获取当前时间
	    long startTime = System.currentTimeMillis();
	    //2、依次向N个节点获取锁
	    List<String> redisNode = null;
	    int successNode = 0;
	    for(String node:redisNode){
	        redis.setNx("cid-orderId","cid-orderId",expire);
	        successNode ++ ;
	    }
	
	    //3、计算像N个节点获取锁时间,(当前时间 - 获取N个节点时间) < 超时时间(30) && 成功节点 >= N/2+1
	    long setnxTime =  System.currentTimeMillis();
	    if((setnxTime - startTime) < expire && successNode > redisNode.size()/2+1){
			//重新计算过期时间，当前时间 - 3、4步的耗时，set过期时间 
	        redis.expire("cid-orderId",expire -(setnxTime - startTime));
	        return true;
	    }
	    return false;
	
	}









数据库成倍扩容 






















​	
​	
​	
​	
​	
​	